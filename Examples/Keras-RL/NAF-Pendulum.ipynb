{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "\n",
    "from gym import envs\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Activation, Flatten, Input, Concatenate\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from rl.agents import NAFAgent\n",
    "from rl.memory import SequentialMemory\n",
    "from rl.random import OrnsteinUhlenbeckProcess\n",
    "from rl.core import Processor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implemntation of Pendulum using a NAF Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PendulumProcessor(Processor):\n",
    "    def process_reward(self, reward):\n",
    "        # The magnitude of the reward can be important. Since each step yields a relatively\n",
    "        # high reward, we reduce the magnitude by two orders.\n",
    "        return reward / 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENV_NAME = 'Pendulum-v0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/b1017579/.local/share/virtualenvs/12._Reinforcement_Learning-DLBnGMow/lib/python3.6/site-packages/gym/envs/registration.py:14: PkgResourcesDeprecationWarning: Parameters to load are deprecated.  Call .resolve and .require separately.\n",
      "  result = entry_point.load(False)\n"
     ]
    }
   ],
   "source": [
    "# Get the environment and extract the number of actions.\n",
    "env = gym.make(ENV_NAME)\n",
    "np.random.seed(123)\n",
    "env.seed(123)\n",
    "assert len(env.action_space.shape) == 1\n",
    "nb_actions = env.action_space.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build all necessary models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_4 (Flatten)          (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 16)                64        \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1)                 17        \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 625\n",
      "Trainable params: 625\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Create value model\n",
    "V_model = Sequential()\n",
    "V_model.add(Flatten(input_shape=(1,) + env.observation_space.shape))\n",
    "V_model.add(Dense(16))\n",
    "V_model.add(Activation('relu'))\n",
    "V_model.add(Dense(16))\n",
    "V_model.add(Activation('relu'))\n",
    "V_model.add(Dense(16))\n",
    "V_model.add(Activation('relu'))\n",
    "V_model.add(Dense(1))\n",
    "V_model.add(Activation('linear'))\n",
    "print(V_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_5 (Flatten)          (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 16)                64        \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 1)                 17        \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 625\n",
      "Trainable params: 625\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Create action value model\n",
    "mu_model = Sequential()\n",
    "mu_model.add(Flatten(input_shape=(1,) + env.observation_space.shape))\n",
    "mu_model.add(Dense(16))\n",
    "mu_model.add(Activation('relu'))\n",
    "mu_model.add(Dense(16))\n",
    "mu_model.add(Activation('relu'))\n",
    "mu_model.add(Dense(16))\n",
    "mu_model.add(Activation('relu'))\n",
    "mu_model.add(Dense(nb_actions))\n",
    "mu_model.add(Activation('linear'))\n",
    "print(mu_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "observation_input (InputLayer)  (None, 1, 3)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "action_input (InputLayer)       (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)             (None, 3)            0           observation_input[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 4)            0           action_input[0][0]               \n",
      "                                                                 flatten_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_21 (Dense)                (None, 32)           160         concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 32)           0           dense_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_22 (Dense)                (None, 32)           1056        activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 32)           0           dense_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_23 (Dense)                (None, 32)           1056        activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 32)           0           dense_23[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_24 (Dense)                (None, 1)            33          activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 1)            0           dense_24[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 2,305\n",
      "Trainable params: 2,305\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Create loss function model\n",
    "action_input = Input(shape=(nb_actions,), name='action_input')\n",
    "observation_input = Input(shape=(1,) + env.observation_space.shape, name='observation_input')\n",
    "x = Concatenate()([action_input, Flatten()(observation_input)])\n",
    "x = Dense(32)(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Dense(32)(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Dense(32)(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Dense(((nb_actions * nb_actions + nb_actions) // 2))(x)\n",
    "x = Activation('linear')(x)\n",
    "L_model = Model(inputs=[action_input, observation_input], outputs=x)\n",
    "print(L_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure agent\n",
    "processor = PendulumProcessor()\n",
    "memory = SequentialMemory(limit=100000, window_length=1)\n",
    "\n",
    "random_process = OrnsteinUhlenbeckProcess(theta=.15, mu=0., sigma=.3, size=nb_actions)\n",
    "agent = NAFAgent(nb_actions=nb_actions, V_model=V_model, L_model=L_model, mu_model=mu_model,\n",
    "                 memory=memory, nb_steps_warmup=100, random_process=random_process,\n",
    "                 gamma=.99, target_model_update=1e-3, processor=processor)\n",
    "agent.compile(Adam(lr=.001, clipnorm=1.), metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 140000 steps ...\n",
      "Interval 1 (0 steps performed)\n",
      "10000/10000 [==============================] - 123s 12ms/step - reward: -0.0093\n",
      "50 episodes - episode_reward: -1.867 [-4.111, -0.019] - loss: 0.000 - mean_absolute_error: 0.007 - mean_q: -0.073\n",
      "\n",
      "Interval 2 (10000 steps performed)\n",
      "10000/10000 [==============================] - 123s 12ms/step - reward: -0.0105\n",
      "50 episodes - episode_reward: -2.096 [-5.379, -0.222] - loss: 0.000 - mean_absolute_error: 0.008 - mean_q: -0.090\n",
      "\n",
      "Interval 3 (20000 steps performed)\n",
      "10000/10000 [==============================] - 123s 12ms/step - reward: -0.0098\n",
      "50 episodes - episode_reward: -1.954 [-7.582, -0.135] - loss: 0.000 - mean_absolute_error: 0.008 - mean_q: -0.108\n",
      "\n",
      "Interval 4 (30000 steps performed)\n",
      "10000/10000 [==============================] - 118s 12ms/step - reward: -0.0084\n",
      "50 episodes - episode_reward: -1.674 [-4.018, -0.028] - loss: 0.000 - mean_absolute_error: 0.008 - mean_q: -0.124\n",
      "\n",
      "Interval 5 (40000 steps performed)\n",
      "10000/10000 [==============================] - 117s 12ms/step - reward: -0.0093\n",
      "50 episodes - episode_reward: -1.866 [-14.944, -0.156] - loss: 0.000 - mean_absolute_error: 0.009 - mean_q: -0.141\n",
      "\n",
      "Interval 6 (50000 steps performed)\n",
      "10000/10000 [==============================] - 117s 12ms/step - reward: -0.0117\n",
      "50 episodes - episode_reward: -2.345 [-15.014, -0.181] - loss: 0.000 - mean_absolute_error: 0.009 - mean_q: -0.160\n",
      "\n",
      "Interval 7 (60000 steps performed)\n",
      "10000/10000 [==============================] - 475s 47ms/step - reward: -0.0205\n",
      "50 episodes - episode_reward: -4.094 [-15.221, -0.068] - loss: 0.001 - mean_absolute_error: 0.010 - mean_q: -0.194\n",
      "\n",
      "Interval 8 (70000 steps performed)\n",
      "10000/10000 [==============================] - 140s 14ms/step - reward: -0.0197\n",
      "50 episodes - episode_reward: -3.938 [-15.202, -0.134] - loss: 0.001 - mean_absolute_error: 0.011 - mean_q: -0.250\n",
      "\n",
      "Interval 9 (80000 steps performed)\n",
      "10000/10000 [==============================] - 132s 13ms/step - reward: -0.0240\n",
      "50 episodes - episode_reward: -4.808 [-15.241, -0.181] - loss: 0.001 - mean_absolute_error: 0.012 - mean_q: -0.317\n",
      "\n",
      "Interval 10 (90000 steps performed)\n",
      "10000/10000 [==============================] - 136s 14ms/step - reward: -0.0178\n",
      "50 episodes - episode_reward: -3.566 [-15.095, -0.174] - loss: 0.002 - mean_absolute_error: 0.013 - mean_q: -0.388\n",
      "\n",
      "Interval 11 (100000 steps performed)\n",
      " 7799/10000 [======================>.......] - ETA: 30s - reward: -0.0094"
     ]
    }
   ],
   "source": [
    "# Fit agent\n",
    "agent.fit(env, nb_steps=140000, visualize=False, verbose=1, nb_max_episode_steps=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After training is done, we save the final weights.\n",
    "agent.save_weights('cdqn_{}_weights.h5f'.format(ENV_NAME), overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, evaluate our algorithm for 5 episodes.\n",
    "agent.test(env, nb_episodes=100, visualize=True, nb_max_episode_steps=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
